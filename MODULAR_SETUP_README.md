# ğŸœï¸ KrackHack 3.0 â€” Off-road Semantic Scene Segmentation (AI/ML Track)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![CUDA](https://img.shields.io/badge/CUDA-12.x-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.x-FF4B4B)
![License](https://img.shields.io/badge/License-MIT-lightgrey)
![Status](https://img.shields.io/badge/Status-Active-success)

A reproducible semantic segmentation pipeline for **autonomous off-road navigation** in desert environments, developed for **KrackHack 3.0 (AI/ML Track)**.

---

## ğŸš€ Live Deployment

**Try our model in action:**  
ğŸ”— **[https://krackhack-inf.streamlit.app/](https://krackhack-inf.streamlit.app/)**

Upload an image and get real-time semantic segmentation predictions!

---

## ğŸ“Œ Table of Contents

* [Project Overview](#project-overview)
* [Repository Structure](#repository-structure)
* [Dataset Setup](#dataset-setup)
* [Environment Setup](#environment-setup)
* [How to Run](#how-to-run)
  * [Training](#training)
  * [Testing / Evaluation](#testing--evaluation)
  * [Using the Interactive Demo](#using-the-interactive-demo)
* [Scripts Folder Organization](#scripts-folder-organization)
* [Modular Code Structure](#modular-code-structure)
* [Pretrained Models](#pretrained-models)
* [Reports & Documentation](#reports--documentation)
* [Tech Stack](#tech-stack)
* [Team](#team)
* [Notes on Reproducibility](#notes-on-reproducibility)

---

## ğŸ§  Project Overview

The objective of this project is to build a **robust multiclass semantic segmentation model** for **off-road desert scenes**, capable of generalizing from **synthetic training data** to **unseen test environments**.

The development followed a failure-driven progression:

* CNN baselines (DeepLabV3+)
* Aggressive domain randomization
* Stabilization via SWA
* Transformer-based SegFormer architecture (final approach)

All experiments, results, and reasoning are documented in the reports included in this repository.

---

## ğŸ“ Repository Structure

### New Modular Architecture

```
KrackHack/
â”œâ”€â”€ README.md                          # Original README (legacy, for reference)
â”œâ”€â”€ MODULAR_SETUP_README.md            # THIS FILE - Judges should read this
â”œâ”€â”€ PIPELINE_MODULES_README.md         # Technical documentation of modules
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ run.txt                            # CUDA install commands
â”œâ”€â”€ pipeline.ipynb                     # Original notebook (NOT REQUIRED - for reference only)
â”‚
â”œâ”€â”€ scripts/                           # All Python modules organized in one folder
â”‚   â”œâ”€â”€ 01_imports_setup.py            # 1. Imports & Environment Setup
â”‚   â”œâ”€â”€ 02_global_config.py            # 2. Global Configuration
â”‚   â”œâ”€â”€ 03_class_id_mapping.py         # 3. Class ID Mapping
â”‚   â”œâ”€â”€ 04_dataset_class.py            # 4. Dataset Class
â”‚   â”œâ”€â”€ 05_data_augmentation.py        # 5. Data Augmentation
â”‚   â”œâ”€â”€ 06_dataloaders.py              # 6. DataLoaders
â”‚   â”œâ”€â”€ 07_model_definition.py         # 7. Model Definition (SegFormer)
â”‚   â”œâ”€â”€ 08_loss_functions.py           # 8. Loss Functions (Dice + Focal)
â”‚   â”œâ”€â”€ 09_metrics.py                  # 9. Metrics (IoU)
â”‚   â”œâ”€â”€ 10_training_loop.py            # 10. Training Loop
â”‚   â”œâ”€â”€ 11_validation_loop.py          # 11. Validation Loop
â”‚   â”œâ”€â”€ 12_training_execution.py       # 12. Training Execution (Main)
â”‚   â”œâ”€â”€ 13_visualization_inference.py  # 13. Visualization & Inference
â”‚   â”œâ”€â”€ 14a_test_dataset_loading.py    # 14A. Test Dataset Loading
â”‚   â”œâ”€â”€ 14b_test_model_loading.py      # 14B. Test Model Loading
â”‚   â”œâ”€â”€ 14c_test_evaluation.py         # 14C. Test Evaluation
â”‚   â”œâ”€â”€ 14d_test_visualization.py      # 14D. Test Visualization
â”‚   â”œâ”€â”€ main_integration.py            # â­ Main training entry point
â”‚   â”œâ”€â”€ test_integration.py            # â­ Main testing entry point
â”‚   â””â”€â”€ app.py                         # Streamlit deployment app
â”‚
â”œâ”€â”€ dataset/                           # Training + validation dataset 
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ Color_Images/
â”‚   â”‚   â””â”€â”€ Segmentation/
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ Color_Images/
â”‚       â””â”€â”€ Segmentation/
â”‚
â”œâ”€â”€ testing_dataset/                   # Blind test dataset 
â”‚   â”œâ”€â”€ Color_Images/
â”‚   â””â”€â”€ Segmentation/
â”‚
â”œâ”€â”€ checkpoints/                       # Saved models (auto-created)
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â””â”€â”€ final_model.pth
â”‚
â”œâ”€â”€ training_curves.png                # Training plots
â””â”€â”€ inference_results.png              # Qualitative results
```

---

## ğŸ“¦ Dataset Setup

### Training & Validation Dataset

Download and extract **into `/dataset`**:

ğŸ”— [Offroad_Segmentation_Training_Dataset.zip](https://storage.googleapis.com/duality-public-share/Hackathons/Duality%20Hackathon/Offroad_Segmentation_Training_Dataset.zip)

Expected structure:

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Color_Images/      (< 1000 images)
â”‚   â””â”€â”€ Segmentation/      (< 1000 masks)
â””â”€â”€ val/
    â”œâ”€â”€ Color_Images/      (< 200 images)
    â””â”€â”€ Segmentation/      (< 200 masks)
```

### Testing Dataset

Download and extract **into `/testing_dataset`**:

Same link as above (contains both training and test splits).

Expected structure:

```
testing_dataset/
â”œâ”€â”€ Color_Images/          (blind test set)
â””â”€â”€ Segmentation/          (ground truth)
```

---

## ğŸ› ï¸ Environment Setup

### 1. Clone or Download Repository

```bash
cd c:\Users\iamda\Desktop\KrackHack\KrackHack

# Verify scripts folder exists
ls scripts/  # Should show all Python modules
```

### 2. Create a Virtual Environment

```bash
python -m venv .venv
```

Activate it:

**Windows**

```bash
.venv\Scripts\activate
```

**Linux / macOS**

```bash
source .venv/bin/activate
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install PyTorch with CUDA Support (CRITICAL)

> âš ï¸ **Important:** After step 3, you MUST run the CUDA installation commands from `run.txt`

```bash
# Check run.txt for the exact command matching your CUDA version
# Example for CUDA 12.1:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

Verify installation:

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

---

## â–¶ï¸ How to Run

### Training

#### Option A: Recommended â€” Use Integration Script

```bash
cd scripts
python main_integration.py
```

**This script:**
- âœ… Creates dataloaders
- âœ… Initializes SegFormer model
- âœ… Runs training with warmup + cosine scheduling
- âœ… Saves best model checkpoint
- âœ… Plots training curves

**Expected output:**
```
============================================================
SegFormer Semantic Segmentation Pipeline
============================================================

[1/4] Creating dataloaders...
Train: 934 samples | Val: 206 samples

[2/4] Initializing model...
Model parameters: 27,546,912

[3/4] Setting up loss and metric...

[4/4] Starting training...
Epoch 1/40 | Train Loss: 1.2345 | Val Loss: 1.0123 | Val mIoU: 0.5234 | LR: 2.00e-05
...
Training complete! Best mIoU: 0.7456
============================================================
```

#### Option B: Manual Step-by-Step (For Debugging)

If you want to run components individually from Python:

```python
import sys
sys.path.insert(0, 'scripts')

# 1. Setup
from imports_setup import device
from global_config import NUM_CLASSES, EPOCHS, ENCODER_LR, DECODER_LR, WEIGHT_DECAY, WARMUP_EPOCHS, CLASS_IDS, SAVE_DIR

# 2. Load data
from dataloaders import create_dataloaders
train_loader, val_loader = create_dataloaders()

# 3. Create model
from model_definition import SegFormerWrapper
model = SegFormerWrapper("nvidia/segformer-b1-finetuned-ade-512-512", NUM_CLASSES).to(device)

# 4. Create loss and metric
from loss_functions import DiceFocalLoss
from metrics import MulticlassIoU
criterion = DiceFocalLoss(NUM_CLASSES)
metric = MulticlassIoU(NUM_CLASSES)

# 5. Train
from training_execution import run_training
history, best_miou = run_training(
    model, train_loader, val_loader, criterion, metric, device,
    EPOCHS, ENCODER_LR, DECODER_LR, WEIGHT_DECAY, WARMUP_EPOCHS,
    CLASS_IDS, SAVE_DIR
)
```

---

### Testing / Evaluation

#### Option A: Recommended â€” Use Test Integration Script

```bash
cd scripts
python test_integration.py
```

**This script:**
- âœ… Loads the best trained model
- âœ… Evaluates on test dataset
- âœ… Computes per-class and mean IoU
- âœ… Visualizes predictions

**Expected output:**
```
============================================================
SegFormer Semantic Segmentation - Testing Pipeline
============================================================

[1/3] Loading test dataset...
Loaded TEST dataset with 156 samples

[2/3] Loading trained model...
Loaded best SegFormer model for testing

[3/3] Evaluating on test set...
Evaluating TEST dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [2:34<00:00, 3.85s/batch]

============================================================
TEST DATASET RESULTS
============================================================
Class   100: IoU = 0.6234
Class   200: IoU = 0.7456
Class   300: IoU = 0.5123
...
Class 10000: IoU = 0.4567
----
Overall TEST mIoU (valid classes only): 0.6234
============================================================
```

#### Option B: Using Evaluation Components Directly

```python
import sys
sys.path.insert(0, 'scripts')

from test_dataset_loading import create_test_loader
from test_model_loading import load_model_for_testing
from test_evaluation import evaluate_on_test
from imports_setup import device
from global_config import NUM_CLASSES

test_loader, test_dataset = create_test_loader("testing_dataset")
model = load_model_for_testing(device, "checkpoints/best_model.pth")
iou_per_class, test_miou = evaluate_on_test(model, test_loader, NUM_CLASSES, device)

print(f"Test mIoU: {test_miou:.4f}")
```

---

### Using the Interactive Demo

#### Live Version (No Installation Needed)

ğŸ”— **Visit:** [https://krackhack-inf.streamlit.app/](https://krackhack-inf.streamlit.app/)

Upload an off-road image and get instant segmentation results with class predictions and confidence visualizations.

#### Running Locally

If you want to run the Streamlit app on your machine:

```bash
cd scripts
streamlit run app.py
```

Then open `http://localhost:8501` in your browser.

**Features:**
- ğŸ“¤ Upload or capture images
- ğŸ¯ Real-time segmentation
- ğŸ¨ Color-coded class predictions
- ğŸ“Š Per-class confidence scores
- ğŸ’¾ Download results as PNG

---

## ğŸ“š Scripts Folder Organization

All Python modules are organized in the **`scripts/`** folder for clean project structure:

```
scripts/
â”œâ”€â”€ 01_imports_setup.py             # Device & imports
â”œâ”€â”€ 02_global_config.py             # Hyperparameters & paths
â”œâ”€â”€ 03_class_id_mapping.py          # Class remapping utilities
â”œâ”€â”€ 04_dataset_class.py             # Dataset class
â”œâ”€â”€ 05_data_augmentation.py         # Augmentations
â”œâ”€â”€ 06_dataloaders.py               # DataLoaders
â”œâ”€â”€ 07_model_definition.py          # SegFormer model
â”œâ”€â”€ 08_loss_functions.py            # Loss functions
â”œâ”€â”€ 09_metrics.py                   # Metrics
â”œâ”€â”€ 10_training_loop.py             # Training loop
â”œâ”€â”€ 11_validation_loop.py           # Validation loop
â”œâ”€â”€ 12_training_execution.py        # Full training pipeline
â”œâ”€â”€ 13_visualization_inference.py   # Inference utilities
â”œâ”€â”€ 14a_test_dataset_loading.py     # Test data loader
â”œâ”€â”€ 14b_test_model_loading.py       # Model loader
â”œâ”€â”€ 14c_test_evaluation.py          # Evaluation metrics
â”œâ”€â”€ 14d_test_visualization.py       # Test visualization
â”œâ”€â”€ main_integration.py             # â­ Main training entry point
â”œâ”€â”€ test_integration.py             # â­ Main testing entry point
â””â”€â”€ app.py                          # Streamlit web app
```

**To run scripts:** Navigate to the `scripts/` folder first:

```bash
cd scripts
python main_integration.py
```

---

## ğŸ“š Modular Code Structure

Each file handles ONE responsibility:

| Module | Purpose |
|--------|---------|
| `01_imports_setup.py` | Device detection, imports |
| `02_global_config.py` | Hyperparameters, paths |
| `03_class_id_mapping.py` | Class ID remapping (100,200,... â†’ 0,1,...) |
| `04_dataset_class.py` | `SegmentationDataset` class |
| `05_data_augmentation.py` | Albumentations transformations |
| `06_dataloaders.py` | PyTorch DataLoaders |
| `07_model_definition.py` | `SegFormerWrapper` model |
| `08_loss_functions.py` | `DiceFocalLoss` |
| `09_metrics.py` | `MulticlassIoU` metric |
| `10_training_loop.py` | `train_one_epoch()` |
| `11_validation_loop.py` | `validate()` |
| `12_training_execution.py` | Full training pipeline |
| `13_visualization_inference.py` | Inference + visualization |
| `14a-14d_test_*.py` | Testing components |

**Benefits:**
- âœ… Easy to modify individual components
- âœ… Clear separation of concerns
- âœ… Reusable across projects
- âœ… Better for debugging

See `PIPELINE_MODULES_README.md` for detailed module documentation.

---

## ğŸ§© Pretrained Models

Final trained checkpoints available here:

ğŸ”— [Google Drive - Trained Models](https://drive.google.com/drive/folders/1cNMqY7EgFQZIi8m4-r8dFjYLib9pa6Nn)

**To use:**

```bash
# Download best_model.pth and place in checkpoints/
cd scripts
python test_integration.py
```

No retraining needed!

---

## ğŸ“„ Reports & Documentation

All technical details, architectural decisions, and analyses:

* ğŸ“˜ **Mid Submission Report**  
  `mid_submission_krackhack.pdf`

* ğŸ“• **Final Report**  
  `FINAL_REPORT_KRACKHACK.pdf`

* ğŸ“– **Module Documentation**  
  `PIPELINE_MODULES_README.md`

---

## âš™ï¸ Tech Stack

| Component | Details |
|-----------|---------|
| **Language** | Python 3.9+ |
| **Framework** | PyTorch 2.x |
| **Model** | SegFormer (MiT-B1) |
| **Pre-training** | ADE20K |
| **Loss** | Dice + Focal |
| **Optimizer** | AdamW |
| **Augmentation** | Albumentations |
| **Scheduler** | Warmup + Cosine Decay |
| **Deployment** | Streamlit |
| **Hardware** | NVIDIA RTX 4060 (8GB VRAM) |

**Key Training Specs:**
- Input: 512Ã—512 RGB images
- Classes: 10 (original IDs: 100, 200, 300, 500, 550, 600, 700, 800, 7100, 10000)
- Batch Size: 4
- Epochs: 40
- Encoder LR: 6e-5
- Decoder LR: 6e-4
- Mixed Precision: âœ… Enabled (AMP)

---

## ğŸ“Š Class Definitions

| ID | Class | Color |
|----|-------|-------|
| 100 | Class 0 | Dark Red |
| 200 | Class 1 | Green |
| 300 | Class 2 | Dark Blue |
| 500 | Class 3 | Yellow |
| 550 | Class 4 | Cyan |
| 600 | Class 5 | Magenta |
| 700 | Class 6 | Bright Green |
| 800 | Class 7 | Blue |
| 7100 | Class 8 | Yellow |
| 10000 | Class 9 | Cyan |

---

## ğŸ‘¥ Team

* **Aryan Sisodiya (Team Leader)**  
  [InfinityXr9](https://github.com/InfinityXr9)

* **Daksh Rathi**  
  [dakshrathi-india](https://github.com/dakshrathi-india)

* **Farhan Alam**  
  [Frozen-afk](https://github.com/Frozen-afk)

* **Tanmay Pratap Singh**  
  [DhmalTPS](https://github.com/DhmalTPS)

---

## â™»ï¸ Notes on Reproducibility

### What We Guarantee

- âœ… Fixed random seeds (where applicable)
- âœ… No test-set leakage during training
- âœ… Validation used strictly for model selection
- âœ… Blind test dataset evaluated post-training only
- âœ… All checkpoints, plots, and metrics documented
- âœ… Modular code for easy experimentation
- âœ… Complete training pipeline in single command

### To Reproduce Results

1. Download datasets (links above)
2. Install dependencies (`requirements.txt` + `run.txt`)
3. Run `cd scripts && python main_integration.py`
4. Compare plots to `training_curves.png`
5. Run `cd scripts && python test_integration.py` for blind test evaluation

### If Something Doesn't Work

<details>
<summary><b>Scripts Not Found / Import Errors</b></summary>

Make sure you're in the correct directory:

```bash
# Navigate to scripts folder
cd scripts

# Then run the script
python main_integration.py
```

If running from parent directory, ensure `scripts/` is in your Python path.

</details>

<details>
<summary><b>CUDA/GPU Issues</b></summary>

```bash
# Verify CUDA
python -c "import torch; print(torch.cuda.is_available())"

# If False, reinstall PyTorch from run.txt
```

</details>

<details>
<summary><b>Out of Memory (OOM)</b></summary>

Edit `scripts/02_global_config.py`:
```python
BATCH_SIZE = 2  # Reduce from 4
SEGFORMER_VARIANT = "nvidia/segformer-b1-finetuned-ade-512-512"  # Use B1 instead of B2
```

</details>

<details>
<summary><b>Dataset Not Found</b></summary>

Verify paths in `scripts/02_global_config.py`:
```python
DATA_ROOT = "../dataset"  # Path from scripts folder to parent
```

Check directory structure from repo root:
```bash
ls dataset/train/Color_Images/  # Should show images
```

Or from scripts folder:
```bash
ls ../dataset/train/Color_Images/  # Should show images
```

</details>

<details>
<summary><b>Model Checkpoint Not Found</b></summary>

Download from Google Drive link above, place in `checkpoints/` folder at repo root:
```
checkpoints/
â”œâ”€â”€ best_model.pth
â””â”€â”€ final_model.pth
```

</details>

---

## ğŸš€ Quick Start Checklist

- [ ] Clone repo
- [ ] Create virtual environment (`.venv`)
- [ ] Install `requirements.txt`
- [ ] Install PyTorch from `run.txt`
- [ ] Download datasets (training + testing)
- [ ] `cd scripts` and run `python main_integration.py` to train
- [ ] `cd scripts` and run `python test_integration.py` to evaluate
- [ ] Visit [Streamlit app](https://krackhack-inf.streamlit.app/) for live demo

---

<p style="text-align:center;">
Made with â¤ï¸ by <b>Aryan Sisodiya</b>, <b>Daksh Rathi</b>, <b>Farhan Alam</b>, and <b>Tanmay Pratap Singh</b> for <b>KrackHack 3.0</b>
</p>
